{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning with VGG16.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PB6B7m1Hq-H",
        "colab_type": "text"
      },
      "source": [
        "# **This notebook helps to show how transfer learning can be implemented with VGG16 and other popular Pretrained Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV16LllgINM2",
        "colab_type": "text"
      },
      "source": [
        "First make the neccesary imports. the Dataset used here for training was gotten from the 2018 Hackexpo organized by @AISaturdayLagos\n",
        "https://www.kaggle.com/c/hackexpo2018-pre-competition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KztwGdlHhvG",
        "colab_type": "code",
        "outputId": "2afe1359-8e7e-4a5a-c798-185b94d74803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Make the neccesary imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "from keras.utils import to_categorical as tc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "808ee0665f0feaf6aec6187d580f8f2e2a0754e5",
        "colab_type": "code",
        "id": "AuD3zAfEYkr1",
        "colab": {}
      },
      "source": [
        "#Install kaggle and upload your kaggle API key in order to pull the competition dataor manually upload it\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "88d4fe85310b06d6669edbe0caef778f2e7c8ff6",
        "colab_type": "code",
        "id": "3RPQyjBvZHS0",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "19f44da7f9ada70902a1e1200ae940076602e686",
        "colab_type": "code",
        "id": "-oyWfxjkZL2w",
        "outputId": "6602d5df-ad22-4070-b089-877ff8a3d43f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!kaggle competitions download -c hackexpo2018"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "404 - Not Found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f9ccc3933646b087ac616ce5a2c90266c9ff3811",
        "colab_type": "code",
        "id": "FkCS2fZpYy4q",
        "colab": {}
      },
      "source": [
        "#Unzip the zip files to their respective folders\n",
        "!unzip -q test.zip\n",
        "!unzip -q train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7d00ba3e9a730a0471f7771d9ee292db696ac6f2",
        "colab_type": "code",
        "id": "2LOt-qfZZRjF",
        "outputId": "d094caab-ae19-4c88-be72-976b9e0f3b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "ls -lah"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 86M\n",
            "drwxr-xr-x 1 root root 4.0K Jan 26 18:41 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Jan 26 18:27 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Jan  8 17:14 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root  43M Jan 26 18:38 hackexpo2018.zip\n",
            "-rw-r--r-- 1 root root   66 Jan 26 18:28 kaggle.json\n",
            "drwxr-xr-x 1 root root 4.0K Jan  8 17:15 \u001b[01;34msample_data\u001b[0m/\n",
            "---------- 1 root root  35K Nov 24 07:01 sample-submission.csv\n",
            "drwxr-xr-x 2 root root  60K Nov 22 08:42 \u001b[01;34mtest\u001b[0m/\n",
            "---------- 1 root root 7.8M Nov 24 07:01 test.zip\n",
            "drwxrwxr-x 6 root root 4.0K Nov 22 08:12 \u001b[01;34mtrain\u001b[0m/\n",
            "---------- 1 root root  35M Nov 24 07:01 train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auN3rcFb3cR3",
        "colab_type": "text"
      },
      "source": [
        "## **Preparing Train Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLrJCTbCVB5U",
        "colab_type": "code",
        "outputId": "f80d5d78-ba5f-40bc-fd8d-15c12ea85712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAIN_FOLDER = \"train\"\n",
        "TEST_FOLDER = \"test\"\n",
        "BATCH_SIZE = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                          validation_split=0.15)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(TRAIN_FOLDER,target_size=(200,200),batch_size=BATCH_SIZE,class_mode=\"categorical\", subset='training')\n",
        "val_data = train_datagen.flow_from_directory(TRAIN_FOLDER,target_size=(200,200),batch_size=BATCH_SIZE,class_mode=\"categorical\", subset='validation')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3060 images belonging to 4 classes.\n",
            "Found 540 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujpHFC_33iRc",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxYOs9it3mfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test/test\n",
        "!mv  -v test/*.jpg test/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_PFxf3p3vSU",
        "colab_type": "code",
        "outputId": "ac3e9c37-7354-4d63-8609-a147882d8c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "gen = datagen.flow_from_directory(r'test',target_size=(200, 200),shuffle=0, class_mode=None,batch_size=1)\n",
        "filenames = gen.filenames\n",
        "names=[]\n",
        "for x in filenames:\n",
        "    names.append(x.split('/')[1])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_MNYr784JIo",
        "colab_type": "code",
        "outputId": "c7cbc0f0-3ad4-4d93-e11d-5671afd836ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"import numpy as np\n",
        "np.shape(gen)\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import numpy as np\\nnp.shape(gen)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90xV-NbFJrwG",
        "colab_type": "text"
      },
      "source": [
        "Make imports for the CNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e482a18608d6d40effbcbbf0cc287da7877e4632",
        "colab_type": "code",
        "id": "VfHAFaxCYm2J",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "00330032932d8488d8683bd75e9cfdfd3067aa1c",
        "colab_type": "code",
        "id": "dMYdXRhgYsd3",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "553c5b608825fcf346c53a8ed676d1370139f314",
        "colab_type": "code",
        "id": "-SPNgz13Yur-",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOFpINXCNj6e",
        "colab_type": "text"
      },
      "source": [
        "The same preprocessing has been applied to all models. the images are color images and have been reshaped to 200x200 for faster computinig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIumQ5mLJ1p6",
        "colab_type": "text"
      },
      "source": [
        "**I would be comparing a Neural Network of 9 Convolution Layers , VGG16, Xception, VGG19, ResNet50, InceptionV3, InceptionResNetV2, MobileNet,  DenseNet, NASNet, MobileNetV2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5kGEMeMNLN",
        "colab_type": "text"
      },
      "source": [
        "**Each would be fed the same set of images and their performace evaluated**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGjjXt73MpAH",
        "colab_type": "text"
      },
      "source": [
        "**DEFINING THE MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0mrU6IcMu4g",
        "colab_type": "text"
      },
      "source": [
        "9 LAYER CONV NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b1c26af0e7137f9f1ef8bae54f415a0e8aae5e3c",
        "colab_type": "code",
        "id": "t7mduYh6Yw_3",
        "colab": {}
      },
      "source": [
        "def conv_layer(x,filters,stride=1):\n",
        "  x = Conv2D(filters,kernel_size=3,padding=\"same\",strides=stride)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  return x\n",
        "  \n",
        "\n",
        "def SimpleNet(input_size=(200,200,3),num_classes=4):\n",
        "  \n",
        "  inputs = Input(shape=input_size)\n",
        "  \n",
        "  outputs = conv_layer(inputs,16,stride=2)\n",
        "  outputs = conv_layer(outputs,32)\n",
        "  outputs = conv_layer(outputs,32)\n",
        "  \n",
        "  outputs = conv_layer(outputs,32,stride=2)\n",
        "  outputs = conv_layer(outputs,64)\n",
        "  outputs = conv_layer(outputs,64)\n",
        "  \n",
        "  outputs = conv_layer(outputs,64,stride=2)\n",
        "  outputs = conv_layer(outputs,128)\n",
        "  outputs = conv_layer(outputs,128)\n",
        "  outputs = Dropout(0.5)(outputs)\n",
        "  \n",
        "  outputs = GlobalAvgPool2D()(outputs)\n",
        "  outputs = Dense(num_classes,activation=\"softmax\")(outputs)\n",
        "  \n",
        "  return Model(inputs=inputs,outputs=outputs)\n",
        "\n",
        "model = SimpleNet()\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5u37UFwO8xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(applications)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "aa57b9122d3e87ec617cf67aebd7a26deb2a2152",
        "colab_type": "code",
        "id": "jw-rinNM7_Ae",
        "outputId": "af336739-1c6c-474e-a583-61fdfcebe272",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from keras import applications\n",
        "model_vgg19 = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "model_xception = applications.xception.Xception(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "model_vgg16 = applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "model_resnet50 = applications.resnet50.ResNet50(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "model_inceptionv3 = applications.inception_v3.InceptionV3(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "model_inceptionv2 = applications.inception_resnet_v2.InceptionResNetV2(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnHmcFzfSnXP",
        "colab_type": "code",
        "outputId": "2670969f-ede2-4d27-ef62-9e80612d0fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model_densenet121 = applications.densenet.DenseNet121(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "\n",
        "model_densenet169 = applications.densenet.DenseNet169(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "model_densenet201 = applications.densenet.DenseNet201(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "\n",
        "model_nasnet_large = applications.nasnet.NASNetLarge(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))\n",
        "model_nasnet_mobile = applications.nasnet.NASNetMobile(weights = \"imagenet\", include_top=False, input_shape = (200, 200, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large-no-top.h5\n",
            "343613440/343610240 [==============================] - 9s 0us/step\n",
            "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5\n",
            "19996672/19993432 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQtp43tFn0Wr",
        "colab_type": "code",
        "outputId": "da8b158e-abb5-40fa-b9d0-8aa8ca59a519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_nasnet_mobile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7f624f748ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-dgPIMXN52q",
        "colab_type": "text"
      },
      "source": [
        "## All hidden layers of the pretrained models havebeen frozen and only the last layer retrained. The last layer is shown below and \"atttached\" to the \"head\" of the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e94ffdad259d4b8c9bcaf39a98a82260f72129bb",
        "colab_type": "code",
        "id": "5DpLuILD7_Ag",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OveX706TM0f",
        "colab_type": "text"
      },
      "source": [
        "Store all models in a list for accesibilty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCcOd4RtTMFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3XRIhABaJkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list = [model_vgg19,model_xception ,model_vgg16,model_resnet50 ,model_inceptionv3,model_inceptionv2,\n",
        "              model_densenet121 ,model_densenet169,model_densenet201 ,model_nasnet_large,model_nasnet_mobile]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxE39uHF0zn1",
        "colab_type": "text"
      },
      "source": [
        "Create a dataframe to hold all the results of the training for analysis later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPTB4_ym0yg0",
        "colab_type": "code",
        "outputId": "3a67882b-fb0f-4572-bfa3-09f823184898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "results_df = pd.DataFrame({'train_acc':[],'train_loss':[],'val_acc':[],'val_loss':[]})\n",
        "results_df = []\n",
        "results_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f23ec468bd73256b1141221f9feec52f3cb26519",
        "colab_type": "code",
        "id": "pcb9v5BJ7_Ak",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def trainer(model):\n",
        "    x = model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation=\"relu\")(x)\n",
        "    predictions = Dense(4, activation=\"softmax\")(x)\n",
        "    # creating the final model \n",
        "    model_final = Model(input = model.input, output = predictions)\n",
        "    # compile the model \n",
        "    model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "    #use checkpointer to keep track of the best model and save it\n",
        "    checkpoint = ModelCheckpoint(filepath='model.weights.best.hdf5',  monitor=\"val_acc\",verbose = 1, save_best_only=True)\n",
        "    #Train the model for only 10 epochs\n",
        "    results = model_final.fit_generator(train_data,steps_per_epoch=int(4000/BATCH_SIZE),epochs=10,validation_data=val_data,validation_steps=int(2000/BATCH_SIZE),callbacks=[checkpoint])\n",
        "    \n",
        "    return results.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwdR6M5IbHw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fc44eb0652440d0d94a591a3ad7b5d96d5b04d1c",
        "colab_type": "code",
        "id": "uokjoKmpZc4j",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "72671617078053352725baf63382c52307b7ef97",
        "colab_type": "code",
        "id": "MkqlwxVKZZ0u",
        "outputId": "190fec9e-f1b8-404c-c26f-781608d24fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "count = 0\n",
        "for model in model_list:\n",
        "    count = count + 1\n",
        "    print(\"Training model \" + str(count) + \" of \" + str(len(model_list)) + \" models\")\n",
        "    remaining_res.append(trainer(model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model 1 of 1 models\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 152s 1s/step - loss: 0.9674 - acc: 0.6032 - val_loss: 0.4793 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.85112, saving model to model.weights.best.hdf5\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 97s 776ms/step - loss: 0.5213 - acc: 0.8069 - val_loss: 0.3173 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.85112 to 0.89757, saving model to model.weights.best.hdf5\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 97s 773ms/step - loss: 0.3674 - acc: 0.8677 - val_loss: 0.2523 - val_acc: 0.9228\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.89757 to 0.92276, saving model to model.weights.best.hdf5\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 97s 775ms/step - loss: 0.2784 - acc: 0.9016 - val_loss: 0.2371 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92276\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 97s 774ms/step - loss: 0.2165 - acc: 0.9246 - val_loss: 0.2226 - val_acc: 0.9224\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92276\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 97s 772ms/step - loss: 0.1812 - acc: 0.9366 - val_loss: 0.2226 - val_acc: 0.9365\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.92276 to 0.93648, saving model to model.weights.best.hdf5\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 96s 771ms/step - loss: 0.1489 - acc: 0.9457 - val_loss: 0.2047 - val_acc: 0.9304\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.93648\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 97s 773ms/step - loss: 0.1280 - acc: 0.9566 - val_loss: 0.2200 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.93648\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 96s 771ms/step - loss: 0.0966 - acc: 0.9707 - val_loss: 0.2164 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.93648\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 97s 773ms/step - loss: 0.0933 - acc: 0.9708 - val_loss: 0.2203 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.93648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ac4c3f657b01deab0c4cce63ac7c296998081421",
        "colab_type": "code",
        "id": "02e8DB6LaN0e",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fcb67327eec4d95d57aef01f257bded82bb3709b",
        "colab_type": "code",
        "id": "_jTkZZxXaRbV",
        "outputId": "e953044b-7a9f-40c1-ad55-eef363333720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "results.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.7678034101111241, 0.8478370221327968],\n",
              " 'loss': [0.6289029064305209, 0.4391732856901119],\n",
              " 'val_acc': [0.8727180531010424, 0.8958333340602193],\n",
              " 'val_loss': [0.37564086778047845, 0.2971737580601035]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c5b06faeff360ca4b7b12d2e4cde42f63a7269c9",
        "colab_type": "code",
        "id": "C6bZuTiw7_A5",
        "colab": {}
      },
      "source": [
        "res = results_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWwWEOXkae7S",
        "colab_type": "code",
        "outputId": "1248e74b-0e65-42e4-9434-6ccd6ea6bfef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "df = pd.DataFrame({'results':remaining_res})\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>results</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'val_loss': [0.4793470764790124, 0.3173487670...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             results\n",
              "0  {'val_loss': [0.4793470764790124, 0.3173487670..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoYdS-LuaqYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('results4.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8930c9f9061218d410e9c5bb5b21e67addf5858d",
        "colab_type": "code",
        "id": "FvSFchHw7_A9",
        "colab": {}
      },
      "source": [
        "!mkdir test/test\n",
        "!mv  -v test/*.jpg test/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "821f218eafaa1dac931e27f7137ca14cf0166392",
        "colab_type": "code",
        "id": "5wvysK7a7_BB",
        "outputId": "1da6ceda-6445-4818-f453-d05b8a8588e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtest\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3379e6c89501d6f03776b0ff9277a050e45c979f",
        "colab_type": "code",
        "id": "wbXlt96c7_BH",
        "scrolled": true,
        "outputId": "41a09304-a992-4826-b322-e0744eb1da83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "gen = datagen.flow_from_directory(r'test',target_size=(200, 200),shuffle=0, class_mode=None,batch_size=1)\n",
        "filenames = gen.filenames\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2653decbd083e8147ceb895c28d944a5c1e7d9c3",
        "colab_type": "code",
        "id": "B2hAbrjV7_BM",
        "scrolled": false,
        "outputId": "38c2c85e-3ca6-427a-9f59-8f7af1a61e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test/00525fa2-c886-4f4d-8bf7-fbb72c6185f5.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4d536f0266460300855089c5d1c544fd7a6bb85d",
        "colab_type": "code",
        "id": "d5duDV367_BP",
        "scrolled": true,
        "outputId": "1ace5378-5f28-49bd-a8b9-8ff81209bcf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'a21fb01b-8fd2-491b-81f7-6643e4eff147.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a43122c7886ba29cab963da31f1d06012e5b3aef",
        "colab_type": "text",
        "id": "MLb2TnTO7_BS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "89b6f0ea5623e05a69a4bc3bcf86cd5269e3e490",
        "colab_type": "code",
        "id": "_kkaNCvq7_BS",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1118bfcae1a5602c2e2e741e7f0647e73ae9dd23",
        "colab_type": "code",
        "id": "p6xbLAbR7_BV",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "009ddedc02a504f4f0a1d49776c2b74a2a749934",
        "colab_type": "code",
        "id": "1o8QENEJ7_BW",
        "colab": {}
      },
      "source": [
        "names=[]\n",
        "for x in filenames:\n",
        "    names.append(x.split('/')[1])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "52181b7663aba8fb7058d51d5390ef0e6d7aac04",
        "colab_type": "code",
        "id": "YMPcuXwd7_BY",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "names[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f6f4968cec28d9341195e3c567fec69915bf6904",
        "colab_type": "code",
        "id": "BdS99kpM7_Bg",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.shape(gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "653c25930361724425990becdcc178237247eea8",
        "colab_type": "code",
        "id": "WJmd4rQ-7_Bi",
        "colab": {}
      },
      "source": [
        "prediction = model_final.predict(gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e8ba70560d55f669fd00bae4e4f75ba9997789ec",
        "colab_type": "code",
        "id": "gb8I4jT_7_Bm",
        "outputId": "b0bf9877-29c7-49d8-d42a-ac5313aa7906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip hackexpo2018.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  hackexpo2018.zip\n",
            "  inflating: sample-submission.csv   \n",
            "  inflating: test.zip                \n",
            "  inflating: train.zip               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSQq68jn5mWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "df = pd.DataFrame(columns=['train_acc','train_loss','val_acc','val_loss'])\n",
        "df1 = pd.read_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7UWqoji_BeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc, train_loss,val_acc,val_loss = ([] for _ in range(4))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70C8-edT_CXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(df1)):\n",
        "    for a in df1.iloc[i,:]:\n",
        "      for x in literal_eval(a.results[i])['train_acc']:\n",
        "        train_acc.append(x)\n",
        "      for x in literal_eval(a.results[i])['train_loss']:\n",
        "        train_loss.append(x)\n",
        "      for x in literal_eval(a.results[i])['val_acc']:\n",
        "        val_acc.append(x)\n",
        "      for x in literal_eval(a.results[i])['val_loss']:\n",
        "        val_loss.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC1xKNeUBZEe",
        "colab_type": "code",
        "outputId": "9ee195ef-2008-4059-a8a1-8ce7a9504c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df1.iloc[1,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "results    {'val_loss': [0.5413931961838179, 0.3603656972...\n",
              "Name: 1, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ary1cyi9BoLY",
        "colab_type": "code",
        "outputId": "537f623b-08f8-4c3f-efa9-8643903f21a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2mkC41JCLAZ",
        "colab_type": "code",
        "outputId": "a059f5d0-2598-4e1e-abed-ed7d09c4bdfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "b['val_loss']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.251345473570224,\n",
              " 0.24074802697613473,\n",
              " 0.21983482024624823,\n",
              " 0.2839752429752454,\n",
              " 0.19585063858942045,\n",
              " 0.2636131054714201,\n",
              " 0.22482005804474892,\n",
              " 0.22865902564329346,\n",
              " 0.23329645960684298,\n",
              " 0.26366004823305744]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgxz7AiQCeeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.head(9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1QLuGcmRFpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}